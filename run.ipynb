{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook run.ipynb to script\n",
      "[NbConvertApp] Writing 7607 bytes to run.py\n"
     ]
    }
   ],
   "source": [
    "## please delete after code convertion in converted py file\n",
    "!jupyter nbconvert --to script run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported utils lib\n",
      "imported models\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1d851f515da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.search'"
     ]
    }
   ],
   "source": [
    "import os,sys,time,glob\n",
    "import numpy as np\n",
    "import utils\n",
    "import argparse\n",
    "import torch\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from models.search import Network\n",
    "from models.arch import Arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"cifar\")\n",
    "parser.add_argument('--data', type=str, default='../data', help=\"location of the data corpus\")\n",
    "parser.add_argument('--batchsz', type=int, default=64, help=\"batch size\")\n",
    "parser.add_argument('--lr', type=float, default=0.025, help='init learning rate')\n",
    "parser.add_argument('--lr_min', type=float, default=0.001, help='min learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--wd',type=float, default=3e-4, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=50, help='report frequency')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='num of training epochs')\n",
    "parser.add_argument('--init_ch', type=int, default=16, help='num of init channels')\n",
    "parser.add_argument('--layers',type=int, default=8, help='total number of layers')\n",
    "parser.add_argument('--model_path',type=str, default='saved_models', help='path to save the model')\n",
    "parser.add_argument('--cutout',action='store_true', default=False, help='use cutout')\n",
    "parser.add_argument('--cutout_len', type=int, default=16, help='cutout length')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0.3, help='drop path probability')\n",
    "parser.add_argument('--exp_path', type=str, default='search', help='experiment name')\n",
    "parser.add_argument('--seed',type=str, default=2, help='set random seed')\n",
    "parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping range')\n",
    "parser.add_argument('--train_portion', type=float, default=0.5, help='portion of training/val splitting')\n",
    "parser.add_argument('--unrolled', action='store_true', default=False, help='use one-step unfolled validation loss')\n",
    "parser.add_argument('--arch_lr', type=float, default=3e-4, help='learning rate for arch encoding')\n",
    "parger.add_argument('--arch_wd', type=float, default=1e-3, help='weight decay for arch encoding')\n",
    "args = parser.parse_args()\n",
    "\n",
    "arge.exp_path += str(args.gpu)\n",
    "utils.create_exp_dir(args.exp_path, scripts_to_save=glob.glob('*.py'))\n",
    "\n",
    "log_format='%(asctime)s %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(args.exp_path, 'log.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)\n",
    "device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    np.random.seed(args.seed)\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.enabled= True\n",
    "    torch.manual_seed(args.seed)\n",
    "    \n",
    "    total, uset = os.popen('nvidia-smi --query-gpu=memory.total,memory.used --format=csv,nounits,noheader'\n",
    "                        ).read().split('\\n')[args.gpu].split(',')\n",
    "    total = int(total)\n",
    "    used = int(used)\n",
    "    \n",
    "    print('GPU:',total,' used:',used)\n",
    "    \n",
    "    args.unrolled = True\n",
    "    \n",
    "    logging.info(\"GPU device = %d\"%args.gpu)\n",
    "    logging.info(\"args = %s\"%args)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    model = Network(args.init_ch, 10, args.layers, creterion).to(device)\n",
    "    \n",
    "    logging.info(\"total param size = %.4f MB\",utils.count_parameters_in_MB(model))\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.wd)\n",
    "    \n",
    "    train_transform, valid_transform = utils._data_transforms_cifar10(args)\n",
    "    train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)\n",
    "    \n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(args.train_portion * num_train))\n",
    "    \n",
    "    train_queue = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=args.batchsz,\n",
    "        sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
    "        pin_memory=True, num_workers=2)\n",
    "\n",
    "#     train_queue = torch.utils.data.DataLoader(\n",
    "#         train_data, batch_size=args.batchsz, shuffle=True, pin_memory=True, num_workers=2)\n",
    "\n",
    "\n",
    "    valid_queue = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=args.batchsz,\n",
    "        sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:]),\n",
    "        pin_memory=True, num_workers=2)\n",
    "\n",
    "#     valid_queue = torch.utils.data.DataLoader(\n",
    "#         valid_data, batch_size=args.batchsz, shuffle=False, pin_memory=True, num_workers=2)\n",
    "    \n",
    "\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer, float(args.epochs), eta_min=args.lr_min)\n",
    "    \n",
    "    arch = Arch(model, args)\n",
    "    \n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        \n",
    "        scheduler.step()\n",
    "        lf = scheduler.get_lr()[0]\n",
    "        logging.info('\\nEpoch: %d lf: %e',epoch, lr)\n",
    "        \n",
    "        genotype = model.genotype()\n",
    "        logging.info('Genotype : %s', genotype)\n",
    "        \n",
    "        train_acc, train_obj = train(train_queue, valid_queue, model, arch, criterion, optimizer, lr)\n",
    "        logging.info('train acc: %f', train_acc)\n",
    "        \n",
    "        valid_acc, valid_obj = infer(valid_queue, model, criterion)\n",
    "        logging.info('valid acc: %f', valid_acc)\n",
    "        \n",
    "        utils.save(model, os.path.join(args.exp_path, 'search.pt'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_queue, valid_queue, model, arch, criterion, optimizer, lr):\n",
    "    \n",
    "    losses = utils.AverageMeter()\n",
    "    top1 = utils.AverageMeter()\n",
    "    top5 = utils.AverageMeter()\n",
    "    \n",
    "    valid_iter = iter(valid_queue)\n",
    "    \n",
    "    for step, (x, target) in enumerate(train_queue):\n",
    "        \n",
    "        batchsz = x.size(0)\n",
    "        model.train()\n",
    "        \n",
    "        x, target = x.to(device), target.cuda(non_blocking=True)\n",
    "        x_search, target_search = next(valid_iter)\n",
    "        x_search, target_search = x_search.to(device), target_search.cuda(non_blocking=True)\n",
    "        \n",
    "        arch.step(x, target, x_search, target_search, lr, optimizer, unrolled=args.unrolled)\n",
    "        \n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        prec1, prec5 = utils.accuracy(logits, target, topk=(1,5))\n",
    "        losses.update(loss.item(), batchsz)\n",
    "        top1.update(prec1.item(), batchsz)\n",
    "        top5.update(prec5.item(), batchsz)\n",
    "        \n",
    "        if step % args.report_freq == 0:\n",
    "            logging.info('Step:%03d loss:%f acc1:%f acc5:%f', step, losses.avg, top1.avg, top5.avg)\n",
    "\n",
    "    return top1.avg, losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(valid_queue, model, criterion):\n",
    "    losses = utils.AverageMeter()\n",
    "    top1 = utils.AverageMeter()\n",
    "    top5 = utils.AverateMeter()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (x, target) in enumerate(valid_queue):\n",
    "            \n",
    "            x, target = x.to(device), target.cuda(non_blocking=True)\n",
    "            batchsz = x.size(0)\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = criterion(logint, target)\n",
    "            \n",
    "            prec1, prec5 = utils.accuracy(logits, target, topk=(1,5))\n",
    "            losses.update(loss.item(), batchsz)\n",
    "            top1.update(prec1.item(), batchsz)\n",
    "            top5.update(prec5.item(), batchsz)\n",
    "            \n",
    "            if step % args.report_freq == 0:\n",
    "                logging.info('>> Validation: %3d %e %f %f', step, losses.avg, top1.avg, top5.avg)\n",
    "                \n",
    "    return top1.avg, losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_torch1_cu10",
   "language": "python",
   "name": "py36_torch1_cu10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
