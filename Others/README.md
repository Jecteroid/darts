# DARTS üéØ playground üßó‚Äç

### This repo is made for ML2's playground projects
> **üåè running environment info** <br>
> `python >= 3.6, pytorch == 1.0, and needs CUDA`
> <br><br>
> **Requirements** <br>
>
> `torch`<br>
> `torchvision`<br>
> `graphviz`<br>
> `numpy`<br>
> `tensorboard`<br>
> `tensorboardx`<br>


<br>

### üöÄ How to search and train?
> üé≤ Simply, you can run DARTS search process with <br> &nbsp;&nbsp;&nbsp;&nbsp; `python run.py --name <your_pjt_name> --dataset <data_NAME> --data_path <your_PATH>` <br><br>
> --> ex) `python run.py --name DARTS_test1 --dataset cifar10 --data_path ../data`
> 
> If you need customize some parameters, check `python run.py -h`
>
> This process can visualize by using tensorboard <br>
> (after run.py execute)`tensorboard --logdir=./searchs/<your_pjt_name>/tb --port=6006`<br>
>
> you can visualize with python visualize.py DARTS

<br>

### üîó Process description. ü•öüê£üê•
#### 1. start setting
> 1. Get some arguments in shell
> 2. Set training environment such as using GPU
> 3. Define model(Network) and optimizers
> 4. Make Dataset(dataloader) -- cifar10
> 5. Set lr scheduler
> 6. and Define arch 


#### 2. under training (alpha searching)
> 1. ‚óã start epoch loop
> 2. ‚îú set lr scheduler 
> 3. ‚îú set genotype
> 4. ‚îú‚óã start training (start step loop (batch streaming))
> 5. ‚îÇ ‚îú‚îÄ dataset setting
> 6. ‚îÇ ‚îú‚óã arch stepping (architecture weight)
> 7. ‚îÇ ‚îÇ ‚îú‚îÄ run virtual step & get gradients
> 8. ‚îÇ ‚îÇ ‚îú‚îÄ compute hessian
> 9. ‚îÇ ‚îÇ ‚îî‚îÄ update alpha gradient
> 10. ‚îÇ ‚îú‚îÄ alpha optimizing
> 11. ‚îÇ ‚îú‚îÄ model training
> 12. ‚îÇ ‚îî‚îÄ model fitting()
> 13. ‚îî‚îÄ validating
> 14. output best model's genotype


#### 3. under training (arch searching)



This project is referred from

- DARTS https://arxiv.org/abs/1806.09055

- git https://github.com/quark0/darts
