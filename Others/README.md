# DARTS üéØ playground üßó‚Äç

### This repo is made for ML2's playground projects
> **üåè running environment info** <br>
> `python >= 3.6, pytorch == 1.0, and needs CUDA`
> <br><br>
> **Requirements** <br>
> ```
  torch
  torchvision
  graphviz
  numpy
  tensorboard
  tensorboardx```

<br>

### üöÄ How to search and train?
> üé≤ Simply, you can run DARTS search process with <br> &nbsp;&nbsp;&nbsp;&nbsp; `python run.py --name <your_pjt_name> --dataset <data_NAME> --data_path <your_PATH>` <br><br>
> --> ex) `python run.py --name DARTS_test1 --dataset cifar10 --data_path ../data`
> 
> If you need customize some parameters, check `python run.py -h`
>
> This process can visualize by using tensorboard <br>
> (after run.py execute)`tensorboard --logdir=./searchs/<your_pjt_name>/tb --port=6006`<br>
>
> you can visualize with python visualize.py DARTS
<br>

### üîó Process description. ü•öüê£üê•
#### 1. start setting
> 1. Get some arguments in shell
> 2. Set training environment such as using GPU
> 3. Define model(Network) and optimizers
> 4. Make Dataset(dataloader) -- cifar10
> 5. Set lr scheduler
> 6. and Define arch 

#### 2. under training (arch searching)
> 1. start epoch loop
> 2. ‚îú set lr scheduler 
> 3. ‚îú set genotype
> 4. ‚îú start training
> 5. ‚é™ ‚îú start step loop (batch streaming)
> 6. ‚é™ ‚é™ ‚îú dataset setting
> 7. ‚é™ ‚é™ ‚îú arch stepping (architecture weight)
> 8. ‚é™ ‚é™ ‚é™ ‚îú 
> 8. ‚é™ ‚é™ ‚é™ ‚îú backward
> 9. ‚é™ ‚é™ ‚é™ ‚îú optimizer step
> 6. ‚é™ ‚é™ ‚îú model training
> 10.‚é™ ‚é™ ‚îú model fitting()
> 11. and making now...

#### 3. under training (arch searching)



This project is referred from

- DARTS https://arxiv.org/abs/1806.09055

- git https://github.com/quark0/darts
