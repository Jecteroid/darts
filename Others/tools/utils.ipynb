{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook utils.ipynb to script\n",
      "[NbConvertApp] Writing 3388 bytes to utils.py\n"
     ]
    }
   ],
   "source": [
    "## please delete below code after convertion in converted script(py) file\n",
    "## + 필요없는 내용 삭제(초반부 1,3~14열, In[ ]형태의 주석제거)\n",
    "!jupyter nbconvert --to script utils.ipynb\n",
    "!sed -i '/^#[ ]In\\[/d' utils.py\n",
    "!sed -i -e '1d;3,14d' utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import numpy as np\n",
    "from tools import preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset, data_path, cutout_length, validation):\n",
    "    dataset = dataset.lower()\n",
    "    \n",
    "    if dataset == 'cifar10':\n",
    "        dset_cls = dset.CIFAR10\n",
    "        n_classes = 10\n",
    "    elif dataset == 'mnist':\n",
    "        dset_cls = dset.MNIST\n",
    "        n_classes = 10\n",
    "    elif dataset == 'fashionmnist':\n",
    "        dset_cls = dset.FashionMNIST\n",
    "        n_classes = 10\n",
    "    else :\n",
    "        raise ValueError(dataset)\n",
    "        \n",
    "    trn_transform, val_transform = preproc.data_transforms(dataset, cutout_length)\n",
    "    trn_data = dset_cls(root=data_path, train=True, download=True, transform=trn_transform)\n",
    "    \n",
    "    shape = trn_data.data.shape\n",
    "    input_channels = 3 if len(shape) == 4 else 1 # 컬러일 경우 shape길이가 4일것임 흑백의 경우는 3\n",
    "    assert shape[1] == shape[2], \"not expected shape = {}\".format(shape)\n",
    "    input_size = shape[1]\n",
    "    \n",
    "    ret = [input_size, input_channels, n_classes, trn_data]\n",
    "    if validation:\n",
    "        ret.append(dset_cls(root=data_path, train=False, download=True, transform=val_transform))\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(file_path):\n",
    "    logger = logging.getLogger('darts')\n",
    "    log_format = '%(asctime)s | %(message)s'\n",
    "    formatter = logging.Formatter(log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "    file_handler = logging.FileHandler(file_path)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    \n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_size(model):\n",
    "    \"\"\" Compute parameter size in Mb\"\"\"\n",
    "    n_params = sum(np.prod(v.size()) for k, v in model.named_parameters() if not k.startswith('aux_head'))\n",
    "    return n_params / 1024. / 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val *n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    \n",
    "    _, pred = output.topk(maxk, 1 ,True, True)\n",
    "    pred = pred.t()\n",
    "    \n",
    "    if target.ndimension() > 1:\n",
    "        terget = terget.max(1)[1]\n",
    "        \n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(1.0 / batch_size))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, ckpt_dir, is_best=False):\n",
    "    filename = os.path.join(ckpt_dir, 'checkpoint.pth.tar')\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        best_filename = os.path.join(ckpt_dir, 'best.pth.tar')\n",
    "        shutil.copyfile(filename, best_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_torch1_cu10",
   "language": "python",
   "name": "py36_torch1_cu10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
